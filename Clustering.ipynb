{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a22dbb27",
      "metadata": {
        "id": "a22dbb27"
      },
      "source": [
        "In the second part of this assignment, we will implement K-means Clustering and kernel K-means Clustering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ce48dff7",
      "metadata": {
        "id": "ce48dff7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "68430d22",
      "metadata": {
        "id": "68430d22"
      },
      "outputs": [],
      "source": [
        "def kmeans(data, k):\n",
        "    num_data = np.shape(data)[0]\n",
        "    cluster_mean = data[np.random.choice(range(num_data), k)]\n",
        "    mean_dist_mat = np.linalg.norm(np.expand_dims(data, axis = 0) - np.expand_dims(cluster_mean, axis = 1), axis = 2)\n",
        "    cluster_allocation = np.argmin(mean_dist_mat, axis = 0)\n",
        "\n",
        "    # Update the clusters until convergence.\n",
        "    updated = True\n",
        "    init_num = 0\n",
        "    while updated:\n",
        "        updated = False\n",
        "\n",
        "        # Calculate the cluster means.\n",
        "        cluster_mean = np.array([np.sum(data[cluster_allocation==i],axis=0)/np.sum(cluster_allocation==i) for i in range(k)])\n",
        "\n",
        "        # Find out which new cluster each data point belongs to\n",
        "        mean_dist_mat = np.linalg.norm(np.expand_dims(data, axis = 0) - np.expand_dims(cluster_mean, axis = 1), axis = 2)\n",
        "        new_cluster_allocation = np.argmin(mean_dist_mat, axis = 0)\n",
        "\n",
        "        # Update the cluster allocation. If nothing changes, exit the loop and return the converged result.\n",
        "        if not np.array_equal(cluster_allocation, new_cluster_allocation):\n",
        "            updated = True\n",
        "            cluster_allocation = new_cluster_allocation\n",
        "        else:\n",
        "            loss = np.sum(np.min(mean_dist_mat, axis = 0))\n",
        "    return cluster_allocation, loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "YhF7ECnGqkmH",
      "metadata": {
        "id": "YhF7ECnGqkmH"
      },
      "outputs": [],
      "source": [
        "def kernel_kmeans(data, k, s, kernel = 'gaussian'):\n",
        "    # The variable s refers to the value of sigma in the Gaussian kernel.\n",
        "    num_data = np.shape(data)[0]\n",
        "    cluster_mean = data[np.random.choice(range(num_data), k)]\n",
        "    mean_dist_mat = np.linalg.norm(np.expand_dims(data, axis = 0) - np.expand_dims(cluster_mean, axis = 1), axis = 2)\n",
        "    cluster_allocation = np.argmin(mean_dist_mat, axis = 0)\n",
        "    # Gaussian kernel\n",
        "    if kernel == 'gaussian':\n",
        "        pre_cal = np.exp(-np.square(metrics.pairwise_distances(data))/(2*(s**2)))\n",
        "    else:\n",
        "        print(\"no such kernel\")\n",
        "\n",
        "    # Update the clusters until convergence.\n",
        "    updated = True\n",
        "    init_num = 0\n",
        "    while updated:\n",
        "        updated = False\n",
        "        \n",
        "        # Find out which new cluster each data point belongs to\n",
        "        mean_dist_mat = [1-2*np.sum(pre_cal[:,cluster_allocation==idx], axis = 1)/np.sum(cluster_allocation==idx)\n",
        "                         +np.sum(pre_cal[cluster_allocation==idx][:, cluster_allocation==idx])/(np.sum(cluster_allocation==idx)**2)\n",
        "                         for idx in range(k)]\n",
        "        new_cluster_allocation = np.argmin(mean_dist_mat, axis = 0)\n",
        "\n",
        "        # Update cluster allocation. If nothing changes, exit the loop and return the converged result.\n",
        "        if not np.array_equal(cluster_allocation, new_cluster_allocation):\n",
        "            updated = True\n",
        "            cluster_allocation = new_cluster_allocation\n",
        "        else:\n",
        "            loss = np.sum(np.min(mean_dist_mat, axis = 0))\n",
        "    return cluster_allocation, loss\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vskWAl3YWgRm",
      "metadata": {
        "id": "vskWAl3YWgRm"
      },
      "source": [
        "Now, implementation is done.\n",
        "\n",
        "Let's check the model's performance with an example we've seen in class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6v5Beqdpx_Z_",
      "metadata": {
        "id": "6v5Beqdpx_Z_"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_circles\n",
        "X, y = make_circles(n_samples=1000, noise = 0.1, factor = 0.3, random_state = 10)\n",
        "plt.figure()\n",
        "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red') \n",
        "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue') \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ww8phoa9ytfB",
      "metadata": {
        "id": "Ww8phoa9ytfB"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "loss = np.inf\n",
        "for _ in range(10):\n",
        "    kmeans_result,loss_tmp = kmeans(X, k=2)\n",
        "    if loss > loss_tmp:\n",
        "        loss = loss_tmp\n",
        "        best_kmeans_result = kmeans_result\n",
        "        score = metrics.normalized_mutual_info_score(y, kmeans_result)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X[kmeans_result == 0,0], X[kmeans_result == 0,1], color = 'red')\n",
        "plt.scatter(X[kmeans_result == 1,0], X[kmeans_result == 1,1], color = 'blue')\n",
        "plt.show()\n",
        "print(\"NMI score of K-means clustering: \",score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jMJ5_cwJy2zK",
      "metadata": {
        "id": "jMJ5_cwJy2zK"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "loss = np.inf\n",
        "for _ in range(10):\n",
        "    kkmeans_result,loss_tmp = kernel_kmeans(X, k=2, s = 0.5)\n",
        "    if loss > loss_tmp:\n",
        "        loss = loss_tmp\n",
        "        best_kkmeans_result = kkmeans_result\n",
        "        score = metrics.normalized_mutual_info_score(y, kkmeans_result)\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X[best_kkmeans_result == 0,0], X[best_kkmeans_result == 0,1], color = 'red')\n",
        "plt.scatter(X[best_kkmeans_result == 1,0], X[best_kkmeans_result == 1,1], color = 'blue')\n",
        "plt.show()\n",
        "print(\"NMI score of kernel K-means clustering: \",score)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
