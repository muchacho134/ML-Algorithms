{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "909cf995",
      "metadata": {
        "id": "909cf995"
      },
      "source": [
        "## &#128187; Homework #1 (Regression) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a031b836",
      "metadata": {
        "id": "a031b836"
      },
      "source": [
        "-------------------------------------------------------------------------------------\n",
        "### \t&#10004; Index\n",
        "#### 1. Lasso Regression and Ridge regression\n",
        "#### 2. Hyperparameters\n",
        "#### 3. Training and Testing the model\n",
        "-------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Lasso regression and Ridge regression\n",
        "\n",
        "In this step, we will implement Lasso regression and Ridge regression without using the regression library (Scikit-Learn). Regression contains GD and loss function for each regression.\n",
        "\n"
      ],
      "metadata": {
        "id": "QEpO5-2attlm"
      },
      "id": "QEpO5-2attlm"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "np.random.seed(123)"
      ],
      "metadata": {
        "id": "PPcAam58UnfZ"
      },
      "id": "PPcAam58UnfZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Regression():\n",
        "  def __init__(self, regularization_weight, ridge):\n",
        "    # When regularization_weight (or lambda) is equal to 0, the model becomes a linear model\n",
        "    self.reg = regularization_weight\n",
        "    self.ridge = ridge\n",
        "  # Function for training\n",
        "  def fit(self, X, Y, epochs, learning_rate):\n",
        "    X_bar = np.insert(X, 0, 1, axis=1)\n",
        "    num_examples, num_features = X_bar.shape\n",
        "    # Init weights and biases\n",
        "    self.W = np.zeros(num_features)\n",
        "\n",
        "    # List for recording losses during training\n",
        "    self.train_loss = []\n",
        "    \n",
        "    # Variable that supports training with Gradient Descent \n",
        "    for ep in range( epochs ):\n",
        "      # Get gradients\n",
        "      raise NotImplementedError\n",
        "      # Update weights\n",
        "      raise NotImplementedError\n",
        "      # Record the loss per epoch\n",
        "      raise NotImplementedError\n",
        "      self.train_loss.append(loss)\n",
        "\n",
        "  # Function for prediction\n",
        "  def predict(self, X):\n",
        "    raise NotImplementedError\n",
        "    return\n",
        "\n",
        "  # Function for calculating the gradient\n",
        "  def calculate_gradient(self, X, Y):\n",
        "    num_examples = X.shape[0]\n",
        "    # Get predictions\n",
        "    raise NotImplementedError\n",
        "    # Calculate gradients\n",
        "    if self.ridge:\n",
        "      raise NotImplementedError\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "    raise NotImplementedError\n",
        "    return\n",
        "\n",
        "  # Function for calculating the loss\n",
        "  def calculate_loss(self, X, Y):\n",
        "    num_examples = X.shape[0]\n",
        "    # Get predictions\n",
        "    pred = self.predict(X)\n",
        "    # Calculate loss\n",
        "    if self.ridge:\n",
        "      raise NotImplementedError\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "    raise NotImplementedError\n",
        "    return \n",
        "\n",
        "  # Function for evaluation\n",
        "  # Metric: Root Mean Square Error (RMSE)\n",
        "  def eval(self, X, Y):\n",
        "    X_bar = np.insert(X, 0, 1, axis=1)\n",
        "    num_examples = X_bar.shape[0]\n",
        "    # Get predictions\n",
        "    raise NotImplementedError\n",
        "    # Calcuate RMSE\n",
        "    raise NotImplementedError\n",
        "    return "
      ],
      "metadata": {
        "id": "5rLWO44qtuP2"
      },
      "id": "5rLWO44qtuP2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data with gaussian noise\n",
        "X = np.random.uniform(-10.0, 10.0, (10000,2))\n",
        "W = np.random.uniform(-1.0, 1.0, 2)\n",
        "b = np.random.uniform(-1.0,1.0, 1)\n",
        "Y = np.dot(X, W) + b + np.random.normal(0,1,10000)"
      ],
      "metadata": {
        "id": "PvPrLXdFt0QW"
      },
      "id": "PvPrLXdFt0QW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size=0.3, random_state=35 )\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=35)\n",
        "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
      ],
      "metadata": {
        "id": "HnPlHsTEt2mX"
      },
      "id": "HnPlHsTEt2mX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Hyperparameters\n",
        "Train the models with different regularization factors, and learning rates. By comparing the loss between each model, we will see the importance of hyperparameters"
      ],
      "metadata": {
        "id": "fAKiZc2807KL"
      },
      "id": "fAKiZc2807KL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init\n",
        "ridge_model_1 = Regression(0.1, True)\n",
        "ridge_model_2 = Regression(0.001, True)\n",
        "\n",
        "# Train \n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "ridge_model_1.fit( X_train, Y_train, epochs, learning_rate)\n",
        "ridge_model_2.fit( X_train, Y_train, epochs, learning_rate)\n",
        "\n",
        "# Plot loss graph\n",
        "loss_1, loss_2 = ridge_model_1.train_loss, ridge_model_2.train_loss\n",
        "\n",
        "x_axis = np.arange(0, len(loss_1))\n",
        "plt.plot(x_axis, loss_1, label='reg = 0.1')\n",
        "plt.plot(x_axis, loss_2, label='reg = 0.001')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.ylim(0,2)\n",
        "plt.title('Ridge Regresssion')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate\n",
        "rmse_1, rmse_2 = ridge_model_1.eval( X_val, Y_val ), ridge_model_2.eval( X_val, Y_val )\n",
        "print(\"Root Mean Square Error (Validation)\")\n",
        "print(f\"reg = 0.1: {rmse_1}\\nreg = 0.001: {rmse_2}\")"
      ],
      "metadata": {
        "id": "zYzunpKB07bz"
      },
      "id": "zYzunpKB07bz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init\n",
        "lasso_model_1 = Regression(0.1, False)\n",
        "lasso_model_2 = Regression(0.001, False)\n",
        "\n",
        "# Train \n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "lasso_model_1.fit( X_train, Y_train, epochs, learning_rate)\n",
        "lasso_model_2.fit( X_train, Y_train, epochs, learning_rate)\n",
        "\n",
        "# Plot loss graph\n",
        "loss_1, loss_2 = lasso_model_1.train_loss, lasso_model_2.train_loss\n",
        "\n",
        "x_axis = np.arange(0, len(loss_1))\n",
        "plt.plot(x_axis, loss_1, label='reg = 0.1')\n",
        "plt.plot(x_axis, loss_2, label='reg = 0.001')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.ylim(0,2)\n",
        "plt.title('Lasso Regresssion')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate\n",
        "rmse_1, rmse_2 = lasso_model_1.eval( X_val, Y_val ), lasso_model_2.eval( X_val, Y_val )\n",
        "print(\"Root Mean Square Error (Validation)\")\n",
        "print(f\"reg = 0.1: {rmse_1}\\nreg = 0.001: {rmse_2}\")"
      ],
      "metadata": {
        "id": "zrfynm0vD2dV"
      },
      "id": "zrfynm0vD2dV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init\n",
        "model = Regression(0.1, True)\n",
        "\n",
        "# Train \n",
        "epochs = 100\n",
        "\n",
        "learning_rate = 0.1\n",
        "model.fit(X_train, Y_train, epochs, learning_rate)\n",
        "loss_1 = model.train_loss\n",
        "rmse_1 = model.eval(X_val, Y_val)\n",
        "\n",
        "learning_rate = 0.01\n",
        "model.fit(X_train, Y_train, epochs, learning_rate)\n",
        "loss_2 = model.train_loss\n",
        "rmse_2 = model.eval(X_val, Y_val)\n",
        "\n",
        "learning_rate = 0.001\n",
        "model.fit(X_train, Y_train, epochs, learning_rate)\n",
        "loss_3 = model.train_loss\n",
        "rmse_3 = model.eval(X_val, Y_val)\n",
        "\n",
        "# Plot loss graph\n",
        "x_axis = np.arange(0, len(loss_1))\n",
        "plt.plot(x_axis, loss_1, label='lr = 0.1')\n",
        "plt.plot(x_axis, loss_2, label='lr = 0.01')\n",
        "plt.plot(x_axis, loss_3, label='lr = 0.001')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.ylim(0,2)\n",
        "plt.title('Ridge Regression')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate\n",
        "print(\"Root Mean Square Error (Validation)\")\n",
        "print(f\"lr = 0.1: {rmse_1}\\nlr = 0.01: {rmse_2}\\nlr = 0.001: {rmse_3}\")"
      ],
      "metadata": {
        "id": "hXSLGT4I09Vs"
      },
      "id": "hXSLGT4I09Vs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init\n",
        "model = Regression(0.1, False)\n",
        "\n",
        "# Train \n",
        "epochs = 100\n",
        "\n",
        "learning_rate = 0.1\n",
        "model.fit(X_train, Y_train, epochs, learning_rate)\n",
        "loss_1 = model.train_loss\n",
        "rmse_1 = model.eval(X_val, Y_val)\n",
        "\n",
        "learning_rate = 0.01\n",
        "model.fit(X_train, Y_train, epochs, learning_rate)\n",
        "loss_2 = model.train_loss\n",
        "rmse_2 = model.eval(X_val, Y_val)\n",
        "\n",
        "learning_rate = 0.001\n",
        "model.fit(X_train, Y_train, epochs, learning_rate)\n",
        "loss_3 = model.train_loss\n",
        "rmse_3 = model.eval(X_val, Y_val)\n",
        "\n",
        "# Plot loss graph\n",
        "x_axis = np.arange(0, len(loss_1))\n",
        "plt.plot(x_axis, loss_1, label='lr = 0.1')\n",
        "plt.plot(x_axis, loss_2, label='lr = 0.01')\n",
        "plt.plot(x_axis, loss_3, label='lr = 0.001')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.ylim(0,2)\n",
        "plt.title('Lasso Regression')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate\n",
        "print(\"Root Mean Square Error (Validation)\")\n",
        "print(f\"lr = 0.1: {rmse_1}\\nlr = 0.01: {rmse_2}\\nlr = 0.001: {rmse_3}\")"
      ],
      "metadata": {
        "id": "Arpd1fo5EfgF"
      },
      "id": "Arpd1fo5EfgF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Training and Testing the model\n",
        "\n",
        "Train each model on the given dataset using the hyperparameters obtained in the previous step, and evaluate the model by root mean square error (RMSE)."
      ],
      "metadata": {
        "id": "KIjahPPWvsNt"
      },
      "id": "KIjahPPWvsNt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Init\n",
        "regularization_weight = 0.001\n",
        "ridge_model = Regression(regularization_weight, True)\n",
        "\n",
        "# Train \n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "ridge_model.fit( X_train, Y_train, epochs, learning_rate)\n",
        "\n",
        "# Plot loss graph\n",
        "ridge_loss = ridge_model.train_loss\n",
        "x_axis = np.arange(0, len(ridge_loss))\n",
        "plt.plot(x_axis, ridge_loss, label='Ridge Regression')\n",
        "plt.title('Ridge Regression')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate\n",
        "print(\"Root Mean Square Error (Test): \", ridge_model.eval( X_test, Y_test ))"
      ],
      "metadata": {
        "id": "DG2AoLkOt3jP"
      },
      "id": "DG2AoLkOt3jP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = ridge_model.W\n",
        "\n",
        "# Plot test dataset \n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(X_test[:500,0], X_test[:500,1], Y_test[:500], color='green')\n",
        "ax.set_xlabel(\"x1\")\n",
        "ax.set_ylabel(\"x2\")\n",
        "ax.set_zlabel(\"y\")\n",
        "\n",
        "# Plot surface of Ridge regression\n",
        "x_axis = np.tile(range(-10,11), (21,1))\n",
        "y_axis = np.tile(range(-10,11), (21,1)).T\n",
        "z_axis = x_axis * weight[1] + y_axis * weight[2] + weight[0]\n",
        "\n",
        "ax.plot_surface(x_axis, y_axis, z_axis, alpha = 0.4)\n",
        "plt.title('Ridge Regression')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WRrNBi-YWqEJ"
      },
      "id": "WRrNBi-YWqEJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Init\n",
        "regularization_weight = 0.001\n",
        "lasso_model = Regression(regularization_weight, False)\n",
        "\n",
        "# Train \n",
        "epochs = 100\n",
        "learning_rate = 0.01\n",
        "lasso_model.fit( X_train, Y_train, epochs, learning_rate)\n",
        "\n",
        "# Plot loss graph\n",
        "lasso_loss = lasso_model.train_loss\n",
        "x_axis = np.arange(0, len(lasso_loss))\n",
        "plt.plot(x_axis, lasso_loss, label='Lasso')\n",
        "plt.title('Lasso Regression')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate\n",
        "print(\"Root Mean Square Error (Test): \", lasso_model.eval( X_test, Y_test ))"
      ],
      "metadata": {
        "id": "oSaynWJyt4em"
      },
      "id": "oSaynWJyt4em",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight = lasso_model.W\n",
        "\n",
        "# Plot test dataset \n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "ax.scatter(X_test[:500,0], X_test[:500,1], Y_test[:500], color='green')\n",
        "ax.set_xlabel(\"x1\")\n",
        "ax.set_ylabel(\"x2\")\n",
        "ax.set_zlabel(\"y\")\n",
        "\n",
        "# Plot surface of Lasso regression\n",
        "x_axis = np.tile(range(-10,11), (21,1))\n",
        "y_axis = np.tile(range(-10,11), (21,1)).T\n",
        "z_axis = x_axis * weight[1] + y_axis * weight[2] + weight[0]\n",
        "\n",
        "ax.plot_surface(x_axis, y_axis, z_axis, alpha = 0.4)\n",
        "plt.title('Lasso Regression')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8CpBL5wHWoar"
      },
      "id": "8CpBL5wHWoar",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}